{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before ensembling: single model accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Six models (best models produced from cv0, cv1, cv2, cv3, cv4 and whole training dataset) were produced in the transfer learning process. Validation accuracy showed that the models' accuracy was around 70%. Later we would show that averaging ensemble could lift the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>CV round</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_loss</th>\n",
       "      <td>0.167847</td>\n",
       "      <td>0.070979</td>\n",
       "      <td>0.085303</td>\n",
       "      <td>0.051624</td>\n",
       "      <td>0.052649</td>\n",
       "      <td>0.085680</td>\n",
       "      <td>0.042939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_acc</th>\n",
       "      <td>0.947100</td>\n",
       "      <td>0.972844</td>\n",
       "      <td>0.970884</td>\n",
       "      <td>0.980929</td>\n",
       "      <td>0.979752</td>\n",
       "      <td>0.970302</td>\n",
       "      <td>0.012226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_loss</th>\n",
       "      <td>1.802394</td>\n",
       "      <td>1.540489</td>\n",
       "      <td>1.852702</td>\n",
       "      <td>1.808886</td>\n",
       "      <td>1.562203</td>\n",
       "      <td>1.713335</td>\n",
       "      <td>0.133567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_acc</th>\n",
       "      <td>0.669805</td>\n",
       "      <td>0.672003</td>\n",
       "      <td>0.691994</td>\n",
       "      <td>0.672214</td>\n",
       "      <td>0.692622</td>\n",
       "      <td>0.679727</td>\n",
       "      <td>0.010308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "CV round           0         1         2         3         4      mean  \\\n",
       "train_loss  0.167847  0.070979  0.085303  0.051624  0.052649  0.085680   \n",
       "train_acc   0.947100  0.972844  0.970884  0.980929  0.979752  0.970302   \n",
       "val_loss    1.802394  1.540489  1.852702  1.808886  1.562203  1.713335   \n",
       "val_acc     0.669805  0.672003  0.691994  0.672214  0.692622  0.679727   \n",
       "\n",
       "CV round         std  \n",
       "train_loss  0.042939  \n",
       "train_acc   0.012226  \n",
       "val_loss    0.133567  \n",
       "val_acc     0.010308  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_score = pd.read_pickle(\"/Users/zhanglingling/Desktop/ML1030/boston_train_evaluate/cv_score.pickle\")\n",
    "cv_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058055</td>\n",
       "      <td>0.978464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss       acc\n",
       "0  0.058055  0.978464"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wholedata_score = pd.read_pickle(\"/Users/zhanglingling/Desktop/ML1030/boston_train_evaluate/wholedata_score.pickle\")\n",
    "wholedata_score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Averaging ensemble\n",
    "### 1.1 Averaging ensemble of all single models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/zhanglingling/Desktop/ML1030/boston_test_prediction/boston.test_bestmodel.hdf5.cv0.prediction.csv',\n",
       " '/Users/zhanglingling/Desktop/ML1030/boston_test_prediction/boston.test_bestmodel.hdf5.cv1.prediction.csv',\n",
       " '/Users/zhanglingling/Desktop/ML1030/boston_test_prediction/boston.test_bestmodel.hdf5.cv2.prediction.csv',\n",
       " '/Users/zhanglingling/Desktop/ML1030/boston_test_prediction/boston.test_bestmodel.hdf5.cv3.prediction.csv',\n",
       " '/Users/zhanglingling/Desktop/ML1030/boston_test_prediction/boston.test_bestmodel.hdf5.cv4.prediction.csv',\n",
       " '/Users/zhanglingling/Desktop/ML1030/boston_test_prediction/boston.test_bestmodel.wholedata.hdf5.prediction.csv']"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_dir = '/Users/zhanglingling/Desktop/ML1030/boston_test_prediction/'\n",
    "file_list = list(glob.glob(predict_dir + \"*.csv*\"))\n",
    "file_list.sort()\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3976, 2)\n",
      "(3975, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_file</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gsv_0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gsv_1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gsv_10.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>gsv_100.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>gsv_1000.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            _file  safety\n",
       "0       gsv_0.jpg       1\n",
       "1       gsv_1.jpg       1\n",
       "10     gsv_10.jpg       0\n",
       "99    gsv_100.jpg       1\n",
       "992  gsv_1000.jpg       1"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv = \"/Users/zhanglingling/Desktop/ML1030/us_safety/boston_test_fetched_with_target.csv\"  \n",
    "test_df = pd.read_csv(test_csv)\n",
    "test_df = test_df.sort_values(\"_file\")\n",
    "target = \"safety\"\n",
    "img_name_col = \"_file\"\n",
    "test_df = test_df[[img_name_col, target]]\n",
    "print(test_df.shape)\n",
    "print(averaged_prediction.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that test_df have 3976 samples whereas averaged_prediction have 3975 samples, that is because one image was not able to be fetched by the Google Street View API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_file</th>\n",
       "      <th>safety</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>pred_safety</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>gsv_1578.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            _file  safety   0   1  pred_safety     _merge\n",
       "640  gsv_1578.jpg       0 NaN NaN          NaN  left_only"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(test_df, averaged_prediction, how='left', on='_file', \n",
    "                   indicator=True)\n",
    "df[df['_merge'] == 'left_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_performance(test_df, file_list):\n",
    "    \n",
    "    #produce averaging ensembled model's prediction - 'averaged_prediction'\n",
    "    df_list = []\n",
    "    for f in file_list:\n",
    "        df = pd.read_csv(f)\n",
    "        df = df.sort_values(\"_file\")\n",
    "        df_list.append(df)\n",
    "        \n",
    "    averaged_prediction = pd.concat(df_list).groupby('_file').mean()\n",
    "    averaged_prediction.reset_index(level=0, inplace=True)\n",
    "    averaged_prediction['pred_safety'] =  np.where(averaged_prediction['0'] > 0.5, 0, 1)\n",
    "    \n",
    "    #prepare y_true, y_pred\n",
    "    df = pd.merge(test_df, averaged_prediction, how='left', on='_file', \n",
    "                   indicator=True)\n",
    "    df[df['_merge'] == 'left_only']\n",
    "    df = df[df['_merge'] == 'both']\n",
    "    df['pred_safety'] = df['pred_safety'].astype(int)\n",
    "    \n",
    "    y_true = df['safety']\n",
    "    y_pred = df['pred_safety']\n",
    "    \n",
    "    #confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    matrix = pd.DataFrame([{'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp}])\n",
    "    \n",
    "    #performance\n",
    "    accuracy = accuracy_score(y_true, y_pred) # accuracy: (tp + tn) / (p + n)\n",
    "    precision = precision_score(y_true, y_pred) # precision tp / (tp + fp)\n",
    "    recall = recall_score(y_true, y_pred) # recall: tp / (tp + fn)\n",
    "    f1 = f1_score(y_true, y_pred) # f1: 2 tp / (2 tp + fp + fn)\n",
    "    performance = pd.DataFrame([{'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 score': f1}])\n",
    "    \n",
    "    return matrix, performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>440</td>\n",
       "      <td>606</td>\n",
       "      <td>1547</td>\n",
       "      <td>1382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fn   fp    tn    tp\n",
       "0  440  606  1547  1382"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.736855</td>\n",
       "      <td>0.725459</td>\n",
       "      <td>0.695171</td>\n",
       "      <td>0.758507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  F1 score  Precision    Recall\n",
       "0  0.736855  0.725459   0.695171  0.758507"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix, performance = matrix_performance(test_df, df_list)\n",
    "display(conf_matrix, performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Averaging ensemble of best models only (cv2, cv4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>472</td>\n",
       "      <td>653</td>\n",
       "      <td>1500</td>\n",
       "      <td>1350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fn   fp    tn    tp\n",
       "0  472  653  1500  1350"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.673989</td>\n",
       "      <td>0.740944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  F1 score  Precision    Recall\n",
       "0  0.716981  0.705882   0.673989  0.740944"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_list = ['/Users/zhanglingling/Desktop/ML1030/boston_test_prediction/boston.test_bestmodel.hdf5.cv2.prediction.csv',\n",
    "             '/Users/zhanglingling/Desktop/ML1030/boston_test_prediction/boston.test_bestmodel.hdf5.cv4.prediction.csv']\n",
    "conf_matrix, performance = matrix_performance(test_df, file_list)\n",
    "display(conf_matrix, performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Averaging ensemble of best models only (cv2, cv4, wholedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>478</td>\n",
       "      <td>602</td>\n",
       "      <td>1551</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fn   fp    tn    tp\n",
       "0  478  602  1551  1344"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.728302</td>\n",
       "      <td>0.713376</td>\n",
       "      <td>0.690647</td>\n",
       "      <td>0.737651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  F1 score  Precision    Recall\n",
       "0  0.728302  0.713376   0.690647  0.737651"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_list = ['/Users/zhanglingling/Desktop/ML1030/boston_test_prediction/boston.test_bestmodel.hdf5.cv2.prediction.csv',\n",
    "             '/Users/zhanglingling/Desktop/ML1030/boston_test_prediction/boston.test_bestmodel.hdf5.cv4.prediction.csv',\n",
    "             '/Users/zhanglingling/Desktop/ML1030/boston_test_prediction/boston.test_bestmodel.wholedata.hdf5.prediction.csv']\n",
    "conf_matrix, performance = matrix_performance(test_df, file_list)\n",
    "display(conf_matrix, performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Conclusion of averaging ensemble\n",
    "\n",
    "Above results showed that the performance of averaging ensemble was better than that of single models; the performance of averaging ensemble of all single models together was better than that of ensembling best models only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Conditional ensemble\n",
    "Next, we would like to print out the confusion matrix of each single model and design a conditional weighting rule and see whether conditional ensemble would further boost the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/zhanglingling/Desktop/ML1030/boston_test_prediction/boston.test_bestmodel.hdf5.cv0.prediction.csv',\n",
       " '/Users/zhanglingling/Desktop/ML1030/boston_test_prediction/boston.test_bestmodel.hdf5.cv1.prediction.csv',\n",
       " '/Users/zhanglingling/Desktop/ML1030/boston_test_prediction/boston.test_bestmodel.hdf5.cv2.prediction.csv',\n",
       " '/Users/zhanglingling/Desktop/ML1030/boston_test_prediction/boston.test_bestmodel.hdf5.cv3.prediction.csv',\n",
       " '/Users/zhanglingling/Desktop/ML1030/boston_test_prediction/boston.test_bestmodel.hdf5.cv4.prediction.csv',\n",
       " '/Users/zhanglingling/Desktop/ML1030/boston_test_prediction/boston.test_bestmodel.wholedata.hdf5.prediction.csv']"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_dir = '/Users/zhanglingling/Desktop/ML1030/boston_test_prediction/'\n",
    "file_list = list(glob.glob(predict_dir + \"*.csv*\"))\n",
    "file_list.sort()\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for f in file_list:\n",
    "    df = pd.read_csv(f)\n",
    "    df = df.sort_values(\"_file\")\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_performance_singlemodel(test_df, data):\n",
    "    \n",
    "    #for a single model, no need to average\n",
    "    prediction = data \n",
    "    prediction['pred_safety'] =  np.where(prediction['0'] > 0.5, 0, 1)\n",
    "    \n",
    "    #prepare y_true, y_pred\n",
    "    df = pd.merge(test_df, prediction, how='left', on='_file', \n",
    "                   indicator=True)\n",
    "    df[df['_merge'] == 'left_only']\n",
    "    df = df[df['_merge'] == 'both']\n",
    "    df['pred_safety'] = df['pred_safety'].astype(int)\n",
    "    \n",
    "    y_true = df['safety']\n",
    "    y_pred = df['pred_safety']\n",
    "    \n",
    "    #confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    matrix = pd.DataFrame([{'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp}])\n",
    "    \n",
    "    #performance\n",
    "    accuracy = accuracy_score(y_true, y_pred) # accuracy: (tp + tn) / (p + n)\n",
    "    precision = precision_score(y_true, y_pred) # precision tp / (tp + fp)\n",
    "    recall = recall_score(y_true, y_pred) # recall: tp / (tp + fn)\n",
    "    f1 = f1_score(y_true, y_pred) # f1: 2 tp / (2 tp + fp + fn)\n",
    "    performance = pd.DataFrame([{'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 score': f1}])\n",
    "    \n",
    "    return matrix, performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_table = pd.DataFrame(columns=['fn','fp','tn', 'tp'])\n",
    "performance_table = pd.DataFrame(columns=['Accuracy', 'F1 score', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_list)):\n",
    "    conf_matrix, performance = matrix_performance_singlemodel(test_df, df_list[i])\n",
    "    conf_matrix_table = pd.concat([conf_matrix_table, conf_matrix])\n",
    "    performance_table = pd.concat([performance_table, performance])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_table.index = ['cv0', 'cv1', 'cv2', 'cv3', 'cv4', 'whole']\n",
    "performance_table.index = ['cv0', 'cv1', 'cv2', 'cv3', 'cv4', 'whole']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cv0</th>\n",
       "      <td>485</td>\n",
       "      <td>704</td>\n",
       "      <td>1449</td>\n",
       "      <td>1337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv1</th>\n",
       "      <td>442</td>\n",
       "      <td>775</td>\n",
       "      <td>1378</td>\n",
       "      <td>1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv2</th>\n",
       "      <td>537</td>\n",
       "      <td>649</td>\n",
       "      <td>1504</td>\n",
       "      <td>1285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv3</th>\n",
       "      <td>653</td>\n",
       "      <td>558</td>\n",
       "      <td>1595</td>\n",
       "      <td>1169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv4</th>\n",
       "      <td>505</td>\n",
       "      <td>684</td>\n",
       "      <td>1469</td>\n",
       "      <td>1317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whole</th>\n",
       "      <td>579</td>\n",
       "      <td>536</td>\n",
       "      <td>1617</td>\n",
       "      <td>1243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fn   fp    tn    tp\n",
       "cv0    485  704  1449  1337\n",
       "cv1    442  775  1378  1380\n",
       "cv2    537  649  1504  1285\n",
       "cv3    653  558  1595  1169\n",
       "cv4    505  684  1469  1317\n",
       "whole  579  536  1617  1243"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cv0</th>\n",
       "      <td>0.700881</td>\n",
       "      <td>0.692208</td>\n",
       "      <td>0.655071</td>\n",
       "      <td>0.733809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv1</th>\n",
       "      <td>0.693836</td>\n",
       "      <td>0.693990</td>\n",
       "      <td>0.640371</td>\n",
       "      <td>0.757409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv2</th>\n",
       "      <td>0.701635</td>\n",
       "      <td>0.684239</td>\n",
       "      <td>0.664426</td>\n",
       "      <td>0.705269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv3</th>\n",
       "      <td>0.695346</td>\n",
       "      <td>0.658777</td>\n",
       "      <td>0.676896</td>\n",
       "      <td>0.641603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv4</th>\n",
       "      <td>0.700881</td>\n",
       "      <td>0.688988</td>\n",
       "      <td>0.658171</td>\n",
       "      <td>0.722832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whole</th>\n",
       "      <td>0.719497</td>\n",
       "      <td>0.690364</td>\n",
       "      <td>0.698707</td>\n",
       "      <td>0.682217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy  F1 score  Precision    Recall\n",
       "cv0    0.700881  0.692208   0.655071  0.733809\n",
       "cv1    0.693836  0.693990   0.640371  0.757409\n",
       "cv2    0.701635  0.684239   0.664426  0.705269\n",
       "cv3    0.695346  0.658777   0.676896  0.641603\n",
       "cv4    0.700881  0.688988   0.658171  0.722832\n",
       "whole  0.719497  0.690364   0.698707  0.682217"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
